// aiPostProcessor.js - AI-powered post-processing for flagged results

// This module can be used to send flagged results to AI models for re-scoring

class AIPostProcessor {
    constructor(config = {}) {
        this.config = {
            provider: config.provider || 'openai', // 'openai' or 'anthropic'
            apiKey: config.apiKey || process.env.OPENAI_API_KEY,
            model: config.model || 'gpt-3.5-turbo',
            enabled: config.enabled !== false,
            threshold: config.threshold || 0.3, // Only process results below this threshold
            maxRetries: config.maxRetries || 2,
            timeout: config.timeout || 10000
        };
    }

    /**
     * Determine if a result should be sent for AI processing
     */
    // shouldProcess(result) {
    //     if (!this.config.enabled) return false;
    //     if (!result || typeof result.confidence !== 'number') return false;
        
    //     // Process if confidence is below threshold but has some potential
    //     if (result.confidence >= this.config.threshold) return false;
    //     if (result.confidence < 0.1) return false; // Too low to be worth processing
        
    //     // Must have at least some codes or strong promotional signals
    //     const hasCodes = result.codes && result.codes.length > 0;
    //     const hasDiscounts = (result.percent_off && result.percent_off.length > 0) || 
    //                        (result.flat_discount && result.flat_discount.length > 0);
    //     const hasPromoLinks = result.links && result.links.some(link => 
    //         /\b(deal|discount|promo|coupon|offer|sale)\b/i.test(link)
    //     );
        
    //     return hasCodes || hasDiscounts || hasPromoLinks;
    // }

    shouldProcess(result) {
    if (!this.config.enabled) return false;
    if (!result || typeof result.confidence !== 'number') return false;
    
    // Process anything below the threshold, except truly empty results
    return result.confidence < this.config.threshold;
}


    /**
     * Generate AI prompt for re-scoring
     */
    generatePrompt(result, originalText) {
        const prompt = `Analyze this YouTube video content for promotional/coupon codes and affiliate marketing.

EXTRACTED DATA:
- Codes found: ${JSON.stringify(result.codes || [])}
- Code confidence: ${JSON.stringify(result.codeConfidence || {})}
- Percentage discounts: ${JSON.stringify(result.percent_off || [])}
- Flat discounts: ${JSON.stringify(result.flat_discount || [])}
- Links: ${JSON.stringify(result.links || [])}
- Current confidence: ${result.confidence}

SAMPLE TEXT (first 500 chars):
"${originalText ? originalText.substring(0, 500) : 'N/A'}"

TASK:
1. Determine if the extracted codes are likely valid promotional/coupon codes
2. Assess if this appears to be sponsored/promotional content
3. Rate confidence from 0.0 to 1.0 where:
   - 0.8+ = Definitely promotional with valid codes
   - 0.5-0.8 = Likely promotional, codes need verification  
   - 0.2-0.5 = Possibly promotional, weak signals
   - 0.0-0.2 = Not promotional content

RESPOND WITH JSON ONLY:
{
  "confidence": 0.0-1.0,
  "reasoning": "brief explanation",
  "validCodes": ["list of codes that seem valid"],
  "isPromotional": true/false,
  "recommendation": "accept/review/reject"
}`;

        return prompt;
    }

    /**
     * Call OpenAI API
     */
    async callOpenAI(prompt, retries = 5) {
    const delay = (ms) => new Promise(res => setTimeout(res, ms));

    for (let i = 0; i < retries; i++) {
        try {
            const response = await fetch('https://api.openai.com/v1/chat/completions', {
                method: 'POST',
                headers: {
                    'Authorization': `Bearer ${this.config.apiKey}`,
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    model: this.config.model,
                    messages: [
                        {
                            role: 'system',
                            content: 'You are an expert at identifying promotional content and coupon codes in YouTube videos. Respond only with valid JSON.'
                        },
                        {
                            role: 'user',
                            content: prompt
                        }
                    ],
                    temperature: 0.1,
                    max_tokens: 300
                })
            });

            if (response.status === 429 && i < retries - 1) {
                const waitTime = 1000 * Math.pow(2, i); // Exponential backoff
                console.warn(`üîÅ OpenAI 429 Rate Limit ‚Äì Retrying in ${waitTime}ms...`);
                await delay(waitTime);
                continue;
            }

            if (!response.ok) {
                throw new Error(`OpenAI API error: ${response.status} ${response.statusText}`);
            }

            const data = await response.json();
            return data.choices[0].message.content;
        } catch (err) {
            if (i < retries - 1) {
                const waitTime = 1000 * Math.pow(2, i);
                console.warn(`‚ö†Ô∏è OpenAI request failed ‚Äì Retrying (${i + 1}/${retries}) in ${waitTime}ms...\nReason: ${err.message}`);
                await delay(waitTime);
            } else {
                throw new Error(`‚ùå OpenAI API failed after ${retries} retries: ${err.message}`);
            }
        }
    }
}


    /**
     * Call Anthropic Claude API
     */
    async callAnthropic(prompt) {
        const response = await fetch('https://api.anthropic.com/v1/messages', {
            method: 'POST',
            headers: {
                'x-api-key': this.config.apiKey,
                'Content-Type': 'application/json',
                'anthropic-version': '2023-06-01'
            },
            body: JSON.stringify({
                model: this.config.model,
                max_tokens: 300,
                messages: [
                    {
                        role: 'user',
                        content: prompt
                    }
                ]
            })
        });

        if (!response.ok) {
            throw new Error(`Anthropic API error: ${response.status} ${response.statusText}`);
        }

        const data = await response.json();
        return data.content[0].text;
    }

    /**
     * Parse AI response and validate
     */
    parseAIResponse(responseText) {
        try {
            // Clean the response (remove markdown code blocks if present)
            let cleanResponse = responseText.trim();
            if (cleanResponse.startsWith('```json')) {
                cleanResponse = cleanResponse.replace(/```json\n?/, '').replace(/\n?```$/, '');
            }
            if (cleanResponse.startsWith('```')) {
                cleanResponse = cleanResponse.replace(/```\n?/, '').replace(/\n?```$/, '');
            }

            const parsed = JSON.parse(cleanResponse);
            
            // Validate required fields
            if (typeof parsed.confidence !== 'number' || 
                parsed.confidence < 0 || parsed.confidence > 1) {
                throw new Error('Invalid confidence value');
            }

            return {
                confidence: parsed.confidence,
                reasoning: parsed.reasoning || 'No reasoning provided',
                validCodes: Array.isArray(parsed.validCodes) ? parsed.validCodes : [],
                isPromotional: Boolean(parsed.isPromotional),
                recommendation: parsed.recommendation || 'review'
            };
        } catch (error) {
            console.log('‚ö†Ô∏è Error parsing AI response:', error.message);
            console.log('Raw response:', responseText);
            return null;
        }
    }

    /**
     * Main processing function
     */
    async processResult(result, originalText = '') {
        if (!this.shouldProcess(result)) {
            console.log('ü§ñ AI processing skipped - criteria not met');
            return result;
        }

        console.log(`ü§ñ Processing with AI (${this.config.provider})...`);
        
        try {
            const prompt = this.generatePrompt(result, originalText);
            let responseText;

            // Call appropriate AI service
            if (this.config.provider === 'anthropic') {
                responseText = await this.callAnthropic(prompt);
            } else {
                responseText = await this.callOpenAI(prompt);
            }

            const aiResult = this.parseAIResponse(responseText);
            
            if (aiResult) {
                console.log(`ü§ñ AI assessment: ${aiResult.confidence.toFixed(2)} confidence`);
                console.log(`ü§ñ Reasoning: ${aiResult.reasoning}`);
                console.log(`ü§ñ Recommendation: ${aiResult.recommendation}`);
                
                // Merge AI results with original
                const enhancedResult = {
                    ...result,
                    confidence: aiResult.confidence,
                    aiEnhanced: true,
                    aiReasoning: aiResult.reasoning,
                    aiValidCodes: aiResult.validCodes,
                    aiRecommendation: aiResult.recommendation,
                    originalConfidence: result.confidence
                };

                // Filter codes based on AI validation if provided
                if (aiResult.validCodes.length > 0) {
                    enhancedResult.codes = result.codes.filter(code => 
                        aiResult.validCodes.includes(code)
                    );
                }

                return enhancedResult;
            } else {
                console.log('‚ö†Ô∏è Failed to parse AI response, returning original result');
                return result;
            }

        } catch (error) {
            console.log('‚ö†Ô∏è AI processing failed:', error.message);
            return result; // Return original result on error
        }
    }

    /**
     * Batch process multiple results
     */
    async processBatch(results, originalTexts = []) {
        const processedResults = [];
        
        for (let i = 0; i < results.length; i++) {
            const result = results[i];
            const originalText = originalTexts[i] || '';
            
            try {
                const processedResult = await this.processResult(result, originalText);
                processedResults.push(processedResult);
                
                // Add delay between API calls to avoid rate limiting
                if (i < results.length - 1) {
                    await new Promise(resolve => setTimeout(resolve, 1000));
                }
            } catch (error) {
                console.log(`‚ö†Ô∏è Error processing result ${i}:`, error.message);
                processedResults.push(result); // Use original on error
            }
        }
        
        return processedResults;
    }

    /**
     * Get processing statistics
     */
    getStats(results) {
        const total = results.length;
        const aiEnhanced = results.filter(r => r.aiEnhanced).length;
        const improved = results.filter(r => 
            r.aiEnhanced && r.confidence > r.originalConfidence
        ).length;
        const degraded = results.filter(r => 
            r.aiEnhanced && r.confidence < r.originalConfidence
        ).length;

        return {
            total,
            aiEnhanced,
            improved,
            degraded,
            improvementRate: aiEnhanced > 0 ? (improved / aiEnhanced * 100).toFixed(1) : 0
        };
    }
}

// Usage example
async function enhanceExtractionWithAI(extractionResult, originalText, aiConfig = {}) {
    const processor = new AIPostProcessor(aiConfig);
    return await processor.processResult(extractionResult, originalText);
}

// Integration with existing extraction pipeline
async function extractFromTranscriptWithAI(transcriptLines, aiConfig = {}) {
    // First run the regular extraction
    const { extractFromTranscript } = require('./textExtract');
    const regularResult = await extractFromTranscript(transcriptLines);
    
    // Then enhance with AI if needed
    const processor = new AIPostProcessor(aiConfig);
    const originalText = Array.isArray(transcriptLines) ? transcriptLines.join(' ') : '';
    
    return await processor.processResult(regularResult, originalText);
}

module.exports = {
    AIPostProcessor,
    enhanceExtractionWithAI,
    extractFromTranscriptWithAI
};